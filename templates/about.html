<!DOCTYPE html>
	<html>
		<head>
			<title>About</title>
			<!-- link to main stylesheet -->
			<link rel= "stylesheet" type= "text/css" href= "{{ url_for('static',filename='styles/main1.css') }}">
		</head>
		<body>
			<nav>
				<nav>
						<ul>

								<li role="presentation"><a href="{{ url_for('static',filename='pages/about.html') }}">About</a></li>
								<li role="presentation"><a href="{{ url_for('static',filename='pages/result.html') }}">Results</a></li>
								<li role="presentation"><a href="{{ url_for('static',filename='pages/visualizations.html') }}">Visualizations</a></li>
								<li role="presentation"><a href="{{ url_for('static',filename='pages/future.html') }}">Future Work</a></li>

						</ul>
				</nav>
			</nav>
			<div class="container">

				<div >
					<h1>About</h1>
					<h3> Data </h3>
					<p> I used the tweepy Python library to gather twitter data. Tweepy provides access to the well documented Twitter API.
						Tweets are structured using JSON, which is easily read using pandas and stored in dataframes.
					    I used a corpus of the 14 popular male athletes, and female athletes, that is a total of 28 athletes, to filter streamed twitter data. For my initial results, submitted on May 1, where after
						running my script for around 8 hours provided <b>~560 MB </b> of data which I used in this preliminary study.
						At this point I have collected around <b>2.02 GB </b>data, over 3 days.
						The data-set has 167,322 unique entries, collected from 90 countries. <br></p>

					<h3> Sentiment Mining </h3>
					<p>I performed sentiment analysis and associated each entry with a positive, negative or neutral sentiment. The tweet <i>text</i> is analyzed a given a polarity from -1 to 1,
					   with anything above 0 positive, below 0 negative, and everything else is neutral. A <i> Naive Bayes </i>[1] analysis is used for classification on an <i>n-gram model</i>[2] of the text.
					   I used the TextBlob, which  is a Python library for processing textual data utilizing the nltk library in Python. The classification is reported to have an accuracy of 0.8. Some examples of the classification:  <br> </p>
					   <ol>
						<li> <b>Positive: </b> 11 years ago today, Kobe Bryant absolutely destroyed Steve Nash. </li>
						<li> <b>Negative: </b> They might've been worse than Iverson 2001 Sixers team...</li>
						<li> <b>Neutral: </b> Remember when Serena williams beat sharapova and a Nigerian paper's headline the next day was "Sharap it's ova"</li>
						</ol>


					<h3> Data Analysis </h3>
				    <p>I used pandas to convert the data into dataframes allowing easier query, sort and statistical operations. I used matplotlib for plotting, scipy and numpy for data analysis. </p>
					<br>
					<h3> Recommender (Future Work) </h3>
				    <p>In a content-based recommender system, keywords are used to describe the items and a user profile is built to indicate the type of item this user likes. In other words, these algorithms try to recommend items that are similar
					    to those that a user liked in the past (or is examining in the present). </p>

					<br>
					<h3> Citations </h3>
					<ol>
						<li> McCallum, Andrew, and Kamal Nigam. "A comparison of event models for naive bayes text classification." AAAI-98 workshop on learning for text categorization. Vol. 752. 1998. </li>
						<li> Cavnar, William B., and John M. Trenkle. "N-gram-based text categorization." Ann Arbor MI 48113.2 (1994): 161-175.</li>
					</ol>
				</div><!-- /.blurb -->

			</div><!-- /.container -->
			<footer >
	    		<ul>
	        		<li><a href="mailto:sreyag28@gmail.com">email</a></li>
	        		<li><a href="https://github.com/SreyaG">github.com/SreyaG</a></li>
				</ul>
			</footer>
		</body>
	</html>
